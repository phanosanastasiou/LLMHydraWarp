# Architecture

This doc outlines a pragmatic MVP architecture for LLM Hydra Warp and a growth path to a production system.

## Goals
- Multi-expert responses per question (Front-End Mixture of Experts for now)
- Public, searchable threads
- Extensible for personas/teams, debate mode, TL;DR summarization

## MVP Architecture
- Next.js App Router (server components + client islands)
- Server Actions (or API routes) for thread CRUD and invoking model calls later
- Postgres (planned) for threads, responses, experts, votes
- Vector store (planned) for search and semantic retrieval
- Mock data (current) to enable fast UX iteration

### Data Model (initial)
- Expert(id, name, username, expertise[], tone)
- Thread(id, title, question, tags[], author)
- ResponseVariant(id, threadId, expertId, content, style, expandedLevel, votes)

### Request Flow
1) Ask page submits CreateThread â†’ server action creates thread and kicks off expert runs (future)
2) Thread page renders existing responses; when expert runs complete, thread updates (future via ISR or websockets)

### MoE Strategy (front-end first)
- Route mock experts based on tags/keywords
- Later: server-side router chooses which experts to run, with budget and diversity constraints

## Production Concerns (future)
- Auth: NextAuth + providers
- Rate limiting: upstash/redis or Postgres-based leaky bucket
- Persistence: Postgres + drizzle/prisma
- Search: Postgres full-text + pgvector
- Observability: OpenTelemetry + structured logs
- Background jobs: queue (e.g., Inngest, Temporal, or simple cron + queue)
- Moderation: policy checks before publishing responses

## UI/UX Notes
- Expandable responses, sub-threads, debate mode, TL;DR summary buttons
- Expert profile drawer, persona builder, team switcher

